diff --git a/chatglm.py b/chatglm.py
index 29e5b5c..ea4d105 100644
--- a/chatglm.py
+++ b/chatglm.py
@@ -1,49 +1,18 @@
-# %% [markdown]
-# # ChatGLM2-6bå¾®è°ƒä¿å§†çº§æ•™ç¨‹
-
-# %% [markdown]
-# ðŸ˜‹ðŸ˜‹å…¬ä¼—å·ç®—æ³•ç¾Žé£Ÿå±‹åŽå°å›žå¤å…³é”®è¯ï¼š**torchkeras**ï¼ŒèŽ·å–æœ¬æ–‡notebookæºä»£ç å’Œæ•°æ®é›†ä¸‹è½½é“¾æŽ¥ã€‚
-
-# %% [markdown]
-# å¹²è´§é¢„è­¦ï¼šè¿™å¯èƒ½æ˜¯ä½ èƒ½å¤Ÿæ‰¾åˆ°çš„æœ€å®¹æ˜“æ‡‚çš„ï¼Œæœ€å®Œæ•´çš„ï¼Œé€‚ç”¨äºŽå„ç§NLPä»»åŠ¡çš„å¼€æºLLMçš„finetuneæ•™ç¨‹~
-
-# %%
-
-
-# %% [markdown]
-# ChatGLM2-6bæ˜¯æ¸…åŽå¼€æºçš„å°å°ºå¯¸LLMï¼Œåªéœ€è¦ä¸€å—æ™®é€šçš„æ˜¾å¡(32Gè¾ƒç¨³å¦¥)å³å¯æŽ¨ç†å’Œå¾®è°ƒï¼Œæ˜¯ç›®å‰ç¤¾åŒºéžå¸¸æ´»è·ƒçš„ä¸€ä¸ªå¼€æºLLMã€‚
-# 
-# æœ¬èŒƒä¾‹ä½¿ç”¨éžå¸¸ç®€å•çš„ï¼Œå¤–å–è¯„è®ºæ•°æ®é›†æ¥å®žæ–½å¾®è°ƒï¼Œè®©ChatGLM2-6bæ¥å¯¹ä¸€æ®µå¤–å–è¯„è®ºåŒºåˆ†æ˜¯å¥½è¯„è¿˜æ˜¯å·®è¯„ã€‚
-# 
-# å¯ä»¥å‘çŽ°ï¼Œç»è¿‡å¾®è°ƒåŽçš„æ¨¡åž‹ï¼Œç›¸æ¯”ç›´æŽ¥ 3-shot-prompt å¯ä»¥å–å¾—æ˜Žæ˜¾æ›´å¥½çš„æ•ˆæžœã€‚
-# 
-# å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡æˆ‘ä»¬ä»¥æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸ºä¾‹ï¼Œå®žé™…ä¸Šï¼Œä»»ä½•NLPä»»åŠ¡ï¼Œä¾‹å¦‚ï¼Œå‘½åå®žä½“è¯†åˆ«ï¼Œç¿»è¯‘ï¼ŒèŠå¤©å¯¹è¯ç­‰ç­‰ï¼Œéƒ½å¯ä»¥é€šè¿‡åŠ ä¸Šåˆé€‚çš„ä¸Šä¸‹æ–‡ï¼Œè½¬æ¢æˆä¸€ä¸ªå¯¹è¯é—®é¢˜ï¼Œå¹¶é’ˆå¯¹æˆ‘ä»¬çš„ä½¿ç”¨åœºæ™¯ï¼Œè®¾è®¡å‡ºåˆé€‚çš„æ•°æ®é›†æ¥å¾®è°ƒChatGLM2.
-# 
-# 
 
-# %% [markdown]
-# å…¬ä¼—å·ç®—æ³•ç¾Žé£Ÿå±‹åŽå°å›žå¤å…³é”®è¯ï¼š torchkerasï¼ŒèŽ·å–æœ¬æ–‡notebookæºä»£ç ï¼Œä»¥åŠwaimaiæ•°æ®é›†ä¸‹è½½é“¾æŽ¥~
-# 
-
-# %%
-
-
-# %% [markdown]
-# ## ã€‡ï¼Œé¢„è®­ç»ƒæ¨¡åž‹
-
-# %% [markdown]
-# æˆ‘ä»¬éœ€è¦ä»Ž https://huggingface.co/THUDM/chatglm2-6b ä¸‹è½½chatglm2çš„æ¨¡åž‹ã€‚
-# 
-# å›½å†…å¯èƒ½é€Ÿåº¦ä¼šæ¯”è¾ƒæ…¢ï¼Œæ€»å…±æœ‰14å¤šä¸ªGï¼Œç½‘é€Ÿä¸å¤ªå¥½çš„è¯ï¼Œå¤§æ¦‚å¯èƒ½éœ€è¦ä¸€ä¸¤ä¸ªå°æ—¶ã€‚
-# 
-# å¦‚æžœç½‘ç»œä¸ç¨³å®šï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨ä»Žè¿™ä¸ªé¡µé¢ä¸€ä¸ªä¸€ä¸ªä¸‹è½½å…¨éƒ¨æ–‡ä»¶ç„¶åŽæ”¾ç½®åˆ° ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ä¾‹å¦‚ 'chatglm2-6b' ä»¥ä¾¿è¯»å–ã€‚
-# 
-# 
 
 # %%
 import copy
 from transformers import  AutoModel,AutoTokenizer
 import os
+import wandb
+wandb.login()
+#ä»¥ä¸‹æ˜¯wandbç›¸å…³å‚æ•°è®¤è¯
+from argparse import Namespace
+config1 = Namespace(
+    batch_size = 4,
+    lr = 1e-3,
+    dropout_p = 0.1,
+    )
 #os.environ['CUDA_VISIBLE_DEVICES'] = '2'
 model_name = "/datas/huggingface/chatglm2-6b" #æˆ–è€…è¿œç¨‹ â€œTHUDM/chatglm2-6bâ€
 tokenizer = AutoTokenizer.from_pretrained(
@@ -93,8 +62,8 @@ print(response)
 his.append(("ï¼•ï¼ å¹´ é‡ å¤§é›ª é˜»æ–­ æ— æ•° æ¸¸å­ å›žå®¶ å½’é€” ä¹Ÿ å½±å“ æ­£å¸¸ ä¸Šä¸‹ç­ -> ","Anxiety"))
 his.append(("å‡‘å·§ é‚£å¤© ä¸‹åˆ æ²¡æœ‰ å¼€è½¦ è€Œ å¤©ç©º é£˜ èµ· é¹…æ¯›å¤§é›ª å¦‚æžœ èµ° ç€ å›žå®¶ è¯´ä¸å®š å°± ä¼š å˜æˆ é›ªäºº å°± ç™¾æ„Ÿäº¤é›† æ—¶å€™ è¾† ç†Ÿæ‚‰ è½¦å­ åœ æˆ‘çš„ é¢å‰ ä¸ ç­‰ è½¦ å°æŸ¯ é€ ä½  ä¸€ç¨‹ å§ -> ","Surprise,Anxiety,Joy"))
 
-# his.append(("çžª å¤§ çœ¼ç› ä¸€çœ‹ å’¦ è¿™ ä¸ å¯å¯ å˜› ä»€ä¹ˆ æ—¶å€™ ä¹° æ–°è½¦ -> ","Surprise"))
-# his.append(("è‡ªç„¶ ä¸ä¼šé”™ è¿‡ è¿™ä¹ˆ å¥½ æœºä¼š é¡ºæ‰‹ æ‹‰å¼€ è½¦é—¨ è½¦ å†… æš–å’Œ ç©ºè°ƒ è®© äºº å€ æ„Ÿ æ¸©é¦¨ é¡¿æ—¶ å¿˜å´ è½¦å¤– å¯’å†· -> ","Joy,Expect,Love"))
+his.append(("çžª å¤§ çœ¼ç› ä¸€çœ‹ å’¦ è¿™ ä¸ å¯å¯ å˜› ä»€ä¹ˆ æ—¶å€™ ä¹° æ–°è½¦ -> ","Surprise"))
+his.append(("è‡ªç„¶ ä¸ä¼šé”™ è¿‡ è¿™ä¹ˆ å¥½ æœºä¼š é¡ºæ‰‹ æ‹‰å¼€ è½¦é—¨ è½¦ å†… æš–å’Œ ç©ºè°ƒ è®© äºº å€ æ„Ÿ æ¸©é¦¨ é¡¿æ—¶ å¿˜å´ è½¦å¤– å¯’å†· -> ","Joy,Expect,Love"))
 
 
 # %% [markdown]
@@ -177,38 +146,40 @@ def before():
     # train.to_csv("train.csv", index=False)
     #data_train.to_csv("train.csv",index=False)
 #before()    
-print(genres)  
-
-# %%
-#å°†ä¸Šä¸‹æ–‡æ•´ç†æˆä¸ŽæŽ¨ç†æ—¶å€™ä¸€è‡´ï¼Œå‚ç…§model.chatä¸­çš„æºç ~
-#model.build_inputs??
-data_train = pd.read_csv('train_sort.csv')
-data_tmp=pd.DataFrame(data_train,columns=['ID', 'Text', 'Labels'])
-
-def build_inputs(query, history,pred):
+#print(genres)  
+
+# %%
+# #å°†ä¸Šä¸‹æ–‡æ•´ç†æˆä¸ŽæŽ¨ç†æ—¶å€™ä¸€è‡´ï¼Œå‚ç…§model.chatä¸­çš„æºç ~
+# #model.build_inputs??
+# data_train = pd.read_csv('train_sort.csv')
+# data_tmp=pd.DataFrame(data_train,columns=['ID', 'Text', 'Labels'])
+
+# def build_inputs(query, history,pred):
+#     prompt = ""
+#     num=0
+#     ans=''
+#     # pred=''
+#     # for index,row in data_tmp.iterrows(): 
+#     #     str11=str(getattr(row, 'Text'))
+#     #     if(str11==query):
+#     #         pred=str(getattr(row, 'Labels'))
+#     #         break
+#     for index,row in data_tmp.iterrows():      
+#         str11=str(getattr(row, 'Labels'))
+#         if(str11==pred):
+#             num=num+1
+#             ans=str(getattr(row, 'Text'))
+#             break
+#     his1=copy.deepcopy(history)
+#     response, history1 = model.chat(tokenizer, ans, history=his1)
+#     for i, (old_query, response) in enumerate(history1):
+#         prompt += "[Round {}]\n\né—®ï¼š{}\n\nç­”ï¼š{}\n\n".format(i + 1, old_query, response)
+#     prompt += "[Round {}]\n\né—®ï¼š{} -> \n\nç­”ï¼š".format(len(history1) + 1, query)
+#     return prompt 
+
+def build_inputs(query, history):
     prompt = ""
-    num=0
-    ans=[]
-    # pred=''
-    # for index,row in data_tmp.iterrows(): 
-    #     str11=str(getattr(row, 'Text'))
-    #     if(str11==query):
-    #         pred=str(getattr(row, 'Labels'))
-    #         break
-    for index,row in data_tmp.iterrows():      
-        str11=str(getattr(row, 'Labels'))
-        if(str11==pred):
-            num=num+1
-            ans.append(str(getattr(row, 'Text')))
-            if(num==2):
-                break
-    his1=copy.deepcopy(history)
-    i=0
-    while i<num:
-        his1.append((ans[i],pred))
-        i=i+1    
-
-    for i, (old_query, response) in enumerate(his1):
+    for i, (old_query, response) in enumerate(history):
         prompt += "[Round {}]\n\né—®ï¼š{}\n\nç­”ï¼š{}\n\n".format(i + 1, old_query, response)
     prompt += "[Round {}]\n\né—®ï¼š{} -> \n\nç­”ï¼š".format(len(history) + 1, query)
     return prompt 
@@ -218,7 +189,7 @@ def build_inputs(query, history,pred):
 
 
 # %%
-df=pd.read_csv("train.csv")
+df=pd.read_csv("train_sort.csv")
 ds_dic = datasets.Dataset.from_pandas(df).train_test_split(
     test_size = 2000,shuffle=True, seed = 43)
 dftrain = ds_dic['train'].to_pandas()
@@ -231,17 +202,18 @@ dftest = ds_dic['test'].to_pandas()
 
 # for i, row in dftrain.iterrows():
 #     dftrain['context'][i]=(build_inputs(row['Text'], his,row['Labels']))
-dftrain['context'] = [build_inputs(x, history=his, pred=pred) for x, pred in zip(dftrain['Text'], dftrain['Labels'])]
+dftrain['context'] = [build_inputs(x,history=his) for x in dftrain['Text']]
+#dftrain['context'] = [build_inputs(x, history=his, pred=pred) for x, pred in zip(dftrain['Text'], dftrain['Labels'])]
 dftrain['target'] = [x for x in dftrain['Labels']]
 dftrain = dftrain[['context','target']]
-dftest['context'] = [build_inputs(x, history=his, pred=pred) for x, pred in zip(dftest['Text'], dftest['Labels'])]
-# dftest['context'] = [build_inputs(x,history=his) for x in dftest['Text']]
+# dftest['context'] = [build_inputs(x, history=his, pred=pred) for x, pred in zip(dftest['Text'], dftest['Labels'])]
+dftest['context'] = [build_inputs(x,history=his) for x in dftest['Text']]
 dftest['target'] = [x for x in dftest['Labels']]
 dftest = dftest[['context','target']]
 
 
 
-print(dftest) 
+print(dftest['context']) 
 
 # %%
 print(dftest['context'][1]) 
@@ -251,33 +223,7 @@ ds_train = datasets.Dataset.from_pandas(dftrain)
 ds_val = datasets.Dataset.from_pandas(dftest)
 
 
-# %%
-
-
-# %% [markdown]
-# ### 2ï¼Œtokenç¼–ç 
 
-# %% [markdown]
-# ä¸ºäº†å°†æ–‡æœ¬æ•°æ®å–‚å…¥æ¨¡åž‹ï¼Œéœ€è¦å°†è¯è½¬æ¢ä¸ºtokenã€‚
-# 
-# ä¹Ÿå°±æ˜¯æŠŠcontextè½¬åŒ–æˆcontext_idsï¼ŒæŠŠtargetè½¬åŒ–æˆtarget_ids. 
-# 
-# åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦å°†context_idså’Œtarget_idsæ‹¼æŽ¥åˆ°ä¸€èµ·ä½œä¸ºæ¨¡åž‹çš„input_idsã€‚
-# 
-# è¿™æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿ
-# 
-# å› ä¸ºChatGLM2åŸºåº§æ¨¡åž‹æ˜¯ä¸€ä¸ªTransformerDecoderç»“æž„ï¼Œæ˜¯ä¸€ä¸ªè¢«é¢„é€‰ç»ƒè¿‡çš„çº¯ç²¹çš„è¯­è¨€æ¨¡åž‹(LLMï¼ŒLarge Lauguage Model)ã€‚
-# 
-# ä¸€ä¸ªçº¯ç²¹çš„è¯­è¨€æ¨¡åž‹ï¼Œæœ¬è´¨ä¸Šåªèƒ½åšä¸€ä»¶äº‹æƒ…ï¼Œé‚£å°±æ˜¯è®¡ç®—ä»»æ„ä¸€æ®µè¯åƒ'äººè¯'çš„æ¦‚çŽ‡ã€‚
-# 
-# æˆ‘ä»¬å°†contextå’Œtargetæ‹¼æŽ¥åˆ°ä¸€èµ·ä½œä¸ºinput_idsï¼Œ ChatGLM2 å°±å¯ä»¥åˆ¤æ–­è¿™æ®µå¯¹è¯åƒ'äººç±»å¯¹è¯'çš„æ¦‚çŽ‡ã€‚
-# 
-# åœ¨è®­ç»ƒçš„æ—¶å€™æˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™çš„æ–¹æ³•æ¥è®©ChatGLM2çš„åˆ¤æ–­æ›´åŠ å‡†ç¡®ã€‚
-# 
-# è®­ç»ƒå®Œæˆä¹‹åŽï¼Œåœ¨é¢„æµ‹çš„æ—¶å€™ï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨è´ªå¿ƒæœç´¢æˆ–è€…æŸæœç´¢çš„æ–¹æ³•æŒ‰ç…§æœ€åƒ"äººç±»å¯¹è¯"çš„æ–¹å¼è¿›è¡Œæ›´åˆç†çš„æ–‡æœ¬ç”Ÿæˆã€‚
-# 
-
-# %%
 from tqdm import tqdm
 import transformers
 
@@ -520,12 +466,19 @@ ckpt_path = 'github_chatglm4_lora_chinese'
 
 
 # %%
+from torchkeras.kerascallbacks import WandbCallback
+wandb_cb = WandbCallback(project='glm_shot',
+                         config=config1,
+                         name=None,
+                         save_code=True,
+                         save_ckpt=True)
 keras_model.fit(train_data = dl_train,
                 val_data = dl_val,
                 epochs=50,patience=3,
                 monitor='val_loss',mode='min',
                 ckpt_path = ckpt_path,
-                mixed_precision='fp16'
+                mixed_precision='fp16',
+                  callbacks = [wandb_cb]
                )
 
 
diff --git a/github_chatglm4_lora_chinese/README.md b/github_chatglm4_lora_chinese/README.md
index 8b5e193..c0f3c5c 100644
--- a/github_chatglm4_lora_chinese/README.md
+++ b/github_chatglm4_lora_chinese/README.md
@@ -126,5 +126,27 @@ library_name: peft
 - PEFT 0.5.0
 - PEFT 0.5.0
 - PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
+- PEFT 0.5.0
 
 - PEFT 0.5.0
diff --git a/github_chatglm4_lora_chinese/adapter_model.bin b/github_chatglm4_lora_chinese/adapter_model.bin
index 63b8e08..7a81d0d 100644
Binary files a/github_chatglm4_lora_chinese/adapter_model.bin and b/github_chatglm4_lora_chinese/adapter_model.bin differ
diff --git a/infer_chatglm.py b/infer_chatglm.py
index 25967b9..db79c36 100644
--- a/infer_chatglm.py
+++ b/infer_chatglm.py
@@ -95,26 +95,33 @@ response, his = model.chat(tokenizer, get_prompt('æ€§èƒ½æ¯” èŽ·å¾— å¤šç§ æµ‹è¯•
 his.append(("ï¼•ï¼ å¹´ é‡ å¤§é›ª é˜»æ–­ æ— æ•° æ¸¸å­ å›žå®¶ å½’é€” ä¹Ÿ å½±å“ æ­£å¸¸ ä¸Šä¸‹ç­ -> ","Anxiety"))
 his.append(("å‡‘å·§ é‚£å¤© ä¸‹åˆ æ²¡æœ‰ å¼€è½¦ è€Œ å¤©ç©º é£˜ èµ· é¹…æ¯›å¤§é›ª å¦‚æžœ èµ° ç€ å›žå®¶ è¯´ä¸å®š å°± ä¼š å˜æˆ é›ªäºº å°± ç™¾æ„Ÿäº¤é›† æ—¶å€™ è¾† ç†Ÿæ‚‰ è½¦å­ åœ æˆ‘çš„ é¢å‰ ä¸ ç­‰ è½¦ å°æŸ¯ é€ ä½  ä¸€ç¨‹ å§ -> ","Surprise,Anxiety,Joy"))
 
-# his.append(("çžª å¤§ çœ¼ç› ä¸€çœ‹ å’¦ è¿™ ä¸ å¯å¯ å˜› ä»€ä¹ˆ æ—¶å€™ ä¹° æ–°è½¦ -> ","Surprise"))
-# his.append(("è‡ªç„¶ ä¸ä¼šé”™ è¿‡ è¿™ä¹ˆ å¥½ æœºä¼š é¡ºæ‰‹ æ‹‰å¼€ è½¦é—¨ è½¦ å†… æš–å’Œ ç©ºè°ƒ è®© äºº å€ æ„Ÿ æ¸©é¦¨ é¡¿æ—¶ å¿˜å´ è½¦å¤– å¯’å†· -> ","Joy,Expect,Love")) 
+his.append(("çžª å¤§ çœ¼ç› ä¸€çœ‹ å’¦ è¿™ ä¸ å¯å¯ å˜› ä»€ä¹ˆ æ—¶å€™ ä¹° æ–°è½¦ -> ","Surprise"))
+his.append(("è‡ªç„¶ ä¸ä¼šé”™ è¿‡ è¿™ä¹ˆ å¥½ æœºä¼š é¡ºæ‰‹ æ‹‰å¼€ è½¦é—¨ è½¦ å†… æš–å’Œ ç©ºè°ƒ è®© äºº å€ æ„Ÿ æ¸©é¦¨ é¡¿æ—¶ å¿˜å´ è½¦å¤– å¯’å†· -> ","Joy,Expect,Love")) 
 
     
-
+#å°†ä¸Šä¸‹æ–‡æ•´ç†æˆä¸ŽæŽ¨ç†æ—¶å€™ä¸€è‡´ï¼Œå‚ç…§model.chatä¸­çš„æºç ~
+#model.build_inputs??
+# def predict(text,pred):
+#     num=0
+#     ans=''    
+#     for index,row in data_tmp.iterrows():      
+#         str11=str(getattr(row, 'Labels'))
+#         if(str11==pred):
+#             num=num+1
+#             ans=str(getattr(row, 'Text'))
+#             break
+#     his1=copy.deepcopy(his)
+#     # response, history1 = model.chat(tokenizer, ans, history=his1)    
+#     response, history = model.chat(tokenizer, f"{text} -> ", history=his1,
+#     temperature=0.01)
+#     return response 
 def predict(text,pred):
-    num=0
-    ans=[]
-    for index,row in data_tmp.iterrows():      
-        str11=str(getattr(row, 'Labels'))
-        if(str11==pred):
-            num=num+1
-            ans.append(str(getattr(row, 'Text')))
-            if(num==2):
-                break
+
     his1=copy.deepcopy(his)
-    i=0
-    while i<num:
-        his1.append((ans[i],pred))
-        i=i+1
+    # i=0
+    # while i<num:
+    #     his1.append((ans[i],pred))
+    #     i=i+1
     response, history = model.chat(tokenizer, f"{text} -> ", history=his1,
     temperature=0.01)
     return response 
